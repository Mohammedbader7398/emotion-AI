{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# ==================================================\n",
    "#                 ÿßŸÑÿ•ÿπÿØÿßÿØÿßÿ™ ÿßŸÑÿπÿßŸÖÿ©\n",
    "# ==================================================\n",
    "MODEL_PATH = \"affectnet_final.keras\"\n",
    "CLASS_NAMES_PATH = \"class_names.txt\"\n",
    "IMG_SIZE = 96\n",
    "\n",
    "# ==================================================\n",
    "#         ÿ™ÿ≠ŸÖŸäŸÑ ŸÜŸÖŸàÿ∞ÿ¨ ÿßŸÑÿ™ÿπŸÑŸÖ ÿßŸÑÿπŸÖŸäŸÇ\n",
    "# ==================================================\n",
    "model = keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "with open(CLASS_NAMES_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    class_names = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    ")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# ==================================================\n",
    "#              ÿ•ÿπÿØÿßÿØ Ÿàÿßÿ¨Ÿáÿ© Tkinter\n",
    "# ==================================================\n",
    "root = tk.Tk()\n",
    "root.title(\"AI Emotion Detection System\")\n",
    "root.geometry(\"1000x650\")\n",
    "root.configure(bg=\"#1e1e1e\")\n",
    "\n",
    "# ===== ÿπŸÜŸàÿßŸÜ =====\n",
    "title = tk.Label(root, text=\"Real-Time Emotion Detection\",\n",
    "                 font=(\"Arial\", 20, \"bold\"),\n",
    "                 fg=\"#00d4ff\", bg=\"#1e1e1e\")\n",
    "title.pack(pady=10)\n",
    "\n",
    "# ===== ÿ•ÿ∑ÿßÿ± ÿßŸÑŸÅŸäÿØŸäŸà =====\n",
    "video_frame = tk.Frame(root, bg=\"#1e1e1e\")\n",
    "video_frame.pack()\n",
    "\n",
    "video_label = tk.Label(video_frame)\n",
    "video_label.pack()\n",
    "\n",
    "# ==================================================\n",
    "#              ŸÑŸàÿ≠ÿ© ÿßŸÑÿ™ÿ≠ŸÉŸÖ\n",
    "# ==================================================\n",
    "control_frame = tk.Frame(root, bg=\"#2b2b2b\")\n",
    "control_frame.pack(fill=\"x\", pady=10)\n",
    "\n",
    "brightness_var = tk.IntVar(value=50)\n",
    "blur_var = tk.IntVar(value=1)\n",
    "threshold_var = tk.IntVar(value=0)\n",
    "emotion_var = tk.BooleanVar(value=True)\n",
    "\n",
    "def styled_scale(label_text, variable, from_, to_):\n",
    "    frame = tk.Frame(control_frame, bg=\"#2b2b2b\")\n",
    "    frame.pack(side=\"left\", padx=20)\n",
    "    tk.Label(frame, text=label_text, fg=\"white\",\n",
    "             bg=\"#2b2b2b\").pack()\n",
    "    scale = ttk.Scale(frame, from_=from_, to=to_,\n",
    "                      variable=variable, orient=\"horizontal\", length=150)\n",
    "    scale.pack()\n",
    "\n",
    "styled_scale(\"Brightness\", brightness_var, 0, 100)\n",
    "styled_scale(\"Blur\", blur_var, 0, 20)\n",
    "styled_scale(\"Threshold\", threshold_var, 0, 255)\n",
    "\n",
    "# ==================================================\n",
    "#                 Ÿàÿ∏ÿßÿ¶ŸÅ ÿßŸÑÿ£ÿ≤ÿ±ÿßÿ±\n",
    "# ==================================================\n",
    "def capture_image():\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        cv2.imwrite(\"captured_image.png\", frame)\n",
    "        print(\"ÿ™ŸÖ ÿ≠ŸÅÿ∏ ÿßŸÑÿµŸàÿ±ÿ© ‚úÖ\")\n",
    "\n",
    "def reset_values():\n",
    "    brightness_var.set(50)\n",
    "    blur_var.set(1)\n",
    "    threshold_var.set(0)\n",
    "\n",
    "def toggle_emotion():\n",
    "    emotion_var.set(not emotion_var.get())\n",
    "\n",
    "def exit_app():\n",
    "    cap.release()\n",
    "    root.destroy()\n",
    "\n",
    "button_frame = tk.Frame(root, bg=\"#1e1e1e\")\n",
    "button_frame.pack(pady=10)\n",
    "\n",
    "tk.Button(button_frame, text=\"üì∏ Capture\",\n",
    "          command=capture_image,\n",
    "          bg=\"#4CAF50\", fg=\"white\",\n",
    "          width=12).pack(side=\"left\", padx=10)\n",
    "\n",
    "tk.Button(button_frame, text=\"üîÑ Reset\",\n",
    "          command=reset_values,\n",
    "          bg=\"#ff9800\", fg=\"white\",\n",
    "          width=12).pack(side=\"left\", padx=10)\n",
    "\n",
    "tk.Button(button_frame, text=\"üß† Emotion ON/OFF\",\n",
    "          command=toggle_emotion,\n",
    "          bg=\"#2196F3\", fg=\"white\",\n",
    "          width=15).pack(side=\"left\", padx=10)\n",
    "\n",
    "tk.Button(button_frame, text=\"‚ùå Exit\",\n",
    "          command=exit_app,\n",
    "          bg=\"#f44336\", fg=\"white\",\n",
    "          width=12).pack(side=\"left\", padx=10)\n",
    "\n",
    "# ==================================================\n",
    "#              ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑŸÅŸäÿØŸäŸà\n",
    "# ==================================================\n",
    "def update_frame():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        return\n",
    "\n",
    "    processed = frame.copy()\n",
    "\n",
    "    # ===== ÿ™ÿ≠ÿ≥ŸäŸÜ ÿ•ÿ∂ÿßÿ°ÿ© ÿ™ŸÑŸÇÿßÿ¶Ÿä (CLAHE) =====\n",
    "    lab = cv2.cvtColor(processed, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    l = clahe.apply(l)\n",
    "    lab = cv2.merge((l,a,b))\n",
    "    processed = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    # ===== ÿ•ÿ∂ÿßÿ°ÿ© ŸäÿØŸàŸäÿ© =====\n",
    "    beta = brightness_var.get() - 50\n",
    "    processed = cv2.convertScaleAbs(processed, alpha=1.0, beta=beta)\n",
    "\n",
    "    # ===== Blur =====\n",
    "    blur_value = int(blur_var.get())\n",
    "    if blur_value > 0:\n",
    "        if blur_value % 2 == 0:\n",
    "            blur_value += 1\n",
    "        processed = cv2.GaussianBlur(processed, (blur_value, blur_value), 0)\n",
    "\n",
    "    # ===== Threshold =====\n",
    "    if threshold_var.get() > 0:\n",
    "        gray_temp = cv2.cvtColor(processed, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh_img = cv2.threshold(\n",
    "            gray_temp, threshold_var.get(), 255, cv2.THRESH_BINARY)\n",
    "        processed = cv2.cvtColor(thresh_img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # ===== ŸÉÿ¥ŸÅ ÿßŸÑŸàÿ¨Ÿá =====\n",
    "    gray = cv2.cvtColor(processed, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if emotion_var.get():\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        for (x, y, w, h) in faces:\n",
    "            roi = processed[y:y+h, x:x+w]\n",
    "            cv2.rectangle(processed, (x, y),\n",
    "                          (x+w, y+h), (0,255,0), 2)\n",
    "\n",
    "            face_resized = cv2.resize(roi, (IMG_SIZE, IMG_SIZE))\n",
    "            face_array = face_resized.astype(\"float32\") / 255.0\n",
    "            face_array = np.expand_dims(face_array, axis=0)\n",
    "\n",
    "            prediction = model.predict(face_array, verbose=0)[0]\n",
    "            best_index = np.argmax(prediction)\n",
    "            emotion = class_names[best_index]\n",
    "            confidence = prediction[best_index] * 100\n",
    "\n",
    "            cv2.putText(processed,\n",
    "                        f\"{emotion} ({confidence:.1f}%)\",\n",
    "                        (x, y-10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.7, (0,255,0), 2)\n",
    "\n",
    "    # ===== ÿπÿ±ÿ∂ ÿØÿßÿÆŸÑ Tk =====\n",
    "    img_rgb = cv2.cvtColor(processed, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(img_rgb)\n",
    "    imgtk = ImageTk.PhotoImage(image=img)\n",
    "\n",
    "    video_label.imgtk = imgtk\n",
    "    video_label.configure(image=imgtk)\n",
    "\n",
    "    root.after(10, update_frame)\n",
    "\n",
    "update_frame()\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
